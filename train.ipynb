{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895b9bfb-df5d-4f31-9bb9-0bf24791c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde8eba5-1cb4-4967-9f12-a904ef8eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, df, image_path, model_initial, transform=None):\n",
    "        self.data = df[\"SENTENCE_NAME\"]\n",
    "        self.labels = df[\"SENTENCE\"]\n",
    "        self.transform = transform\n",
    "        self.image_path = image_path\n",
    "        self.videos = []\n",
    "        self.labels = []\n",
    "        self.map_index = []\n",
    "        for idx in tqdm.tqdm(range(len(self.data))):\n",
    "            if(idx > 14000):\n",
    "                break\n",
    "            if not os.path.exists(image_path+self.data.iloc[idx]+\".npy\"):\n",
    "                continue\n",
    "            with open(self.image_path+self.data.iloc[idx]+\".npy\", 'rb') as f:\n",
    "                video = torch.tensor(np.load(f))\n",
    "                label = torch.tensor(np.load(f))\n",
    "                self.videos.append(video)\n",
    "                self.labels.append(label)\n",
    "            self.map_index.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.videos[idx], self.labels[idx]\n",
    "\n",
    "def load_dataset(path, image_path, transform=None):\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "    dataset = CSVDataset(df, image_path, transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455e2df2-657d-49f8-8873-168a041bc3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 14001/31165 [07:56<09:44, 29.37it/s]\n",
      "100%|██████████| 1741/1741 [00:59<00:00, 29.25it/s]\n",
      "100%|██████████| 2357/2357 [01:20<00:00, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  13924\n",
      "Val dataset size:  1739\n",
      "Test dataset size:  2343\n",
      "video clip size:  torch.Size([20, 3, 180, 320]) torch.Size([20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        Resize((180, 320), antialias=False)\n",
    "    ])\n",
    "\n",
    "train_dataset = load_dataset(\"data/train.csv\", \"data/train_npy/\", transform)\n",
    "val_dataset = load_dataset(\"data/val.csv\", \"data/val_npy/\", transform)\n",
    "test_dataset = load_dataset(\"data/test.csv\", \"data/test_npy/\", transform)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#print info about datasets\n",
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Val dataset size: \", len(val_dataset))\n",
    "print(\"Test dataset size: \", len(test_dataset))\n",
    "print(\"video clip size: \", val_dataset[0][0].size(), val_dataset[0][1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80340265-de76-4daf-95cb-eca72cfb2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=56, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=56, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=56, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e99fe25-6aef-43e2-a84e-761a02ee2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertTokenizer\n",
    "#from torcheval.metrics.functional import bleu_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "import time\n",
    "\n",
    "class VideoToText(nn.Module):\n",
    "    def __init__(self, cnn, hidden_size, output_size, num_layers):\n",
    "        super(VideoToText, self).__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.cnn = cnn\n",
    "        self.encoder = nn.LSTM(input_size=cnn.fc.in_features, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=output_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(output_size, len(self.tokenizer.get_vocab()))\n",
    "        #remove last layer of cnn\n",
    "        self.cnn.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, src):\n",
    "        #print(src.shape)\n",
    "        batch_size, seq_len, c, h, w = src.shape\n",
    "        src = src.reshape(batch_size*seq_len, c, h, w)\n",
    "\n",
    "        src = self.cnn(src)\n",
    "        src = src.reshape(batch_size, seq_len, -1)\n",
    "        src, (hidden, cell) = self.encoder(src)\n",
    "        src, (hidden, cell) = self.decoder(src)\n",
    "        src = self.fc(src)\n",
    "        return src\n",
    "\n",
    "#train model function\n",
    "def train(model, train_dataloader, val_dataloader, epochs, lr, device):\n",
    "    tokenizer = model.tokenizer\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        start = time.time()\n",
    "        avg_bleu = 0\n",
    "        avg_loss = 0\n",
    "        cnt = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "            #print(inputs, labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            \n",
    "            label_text = tokenizer.decode(labels[0].to(torch.long), skip_special_tokens=True)\n",
    "            output_text = tokenizer.decode(outputs[0].argmax(dim=1), skip_special_tokens=True)\n",
    "\n",
    "\n",
    "            outputs = outputs.permute(0, 2, 1)\n",
    "            #print(labels.shape, outputs.shape)\n",
    "\n",
    "            if(labels.shape[1] < outputs.shape[2]):\n",
    "                outputs = outputs[:, :, :labels.shape[1]]\n",
    "            if(labels.shape[1] > outputs.shape[2]):\n",
    "                labels = labels[:, :outputs.shape[2]]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            curr = time.time()\n",
    "            score = sentence_bleu([label_text], output_text, smoothing_function=SmoothingFunction().method4)\n",
    "            avg_bleu += score\n",
    "            avg_loss += loss.item()\n",
    "            cnt += 1\n",
    "            print(\"\\rEpoch: {}/{}, Batch: {}/{}, Loss: {:.4f}, Bleu: {:.5f}, Elapsed: {:.2f} sec\".format(epoch+1, epochs, i+1, len(train_dataloader), loss.item(), score, curr-start), end=\"\")\n",
    "        print(\"\\rEpoch: {}/{}, Loss: {:.4f}, Bleu: {:.5f}, Elapsed: {:.2f} sec\".format(epoch+1, epochs, avg_loss/cnt, avg_bleu/cnt, curr-start))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            avgloss = 0\n",
    "            avgbleu = 0\n",
    "            count = 0\n",
    "            start = time.time()\n",
    "            for i, (inputs, labels) in enumerate(val_dataloader):\n",
    "                if(i > 1):\n",
    "                    break\n",
    "                count = count+1\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.permute(0, 2, 1)\n",
    "                if(labels.shape[1] < outputs.shape[2]):\n",
    "                    outputs = outputs[:, :, :labels.shape[1]]\n",
    "                if(labels.shape[1] > outputs.shape[2]):\n",
    "                    labels = labels[:, :outputs.shape[2]]\n",
    "                loss = criterion(outputs, labels)\n",
    "                label_text = [[tokenizer.decode(x.to(torch.long), skip_special_tokens=True)] for x in labels]\n",
    "                output_text = [tokenizer.decode(x.argmax(dim=1), skip_special_tokens=True) for x in outputs]\n",
    "                score = corpus_bleu(label_text, output_text, smoothing_function=SmoothingFunction().method4)\n",
    "                avgbleu += score\n",
    "                avgloss += loss.item()\n",
    "            print(\"Epoch: {}/{}, Loss: {:.4f}, Bleu: {:.5f}, Elapsed Time: {:.4f}\\n\".format(epoch+1, epochs, avgloss/count, avgbleu/count, time.time()-start))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd5239b-761a-474a-89cb-224144fcf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "cnn_extractor = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = VideoToText(cnn_extractor, hidden_size=512, output_size=512, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb6a42-10bd-40ac-96c7-ceb18ded562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/250, Loss: 5.0487, Bleu: 0.00374, Elapsed: 123.65 secpsed: 123.65 sec\n",
      "Epoch: 1/250, Loss: 4.7406, Bleu: 0.00000, Elapsed Time: 68.3088\n",
      "\n",
      "Epoch: 2/250, Loss: 4.7620, Bleu: 0.01093, Elapsed: 114.27 secpsed: 114.27 sec\n",
      "Epoch: 2/250, Loss: 4.6869, Bleu: 0.00001, Elapsed Time: 41.0334\n",
      "\n",
      "Epoch: 3/250, Loss: 4.7276, Bleu: 0.01461, Elapsed: 114.43 secpsed: 114.43 sec\n",
      "Epoch: 3/250, Loss: 4.9421, Bleu: 0.00001, Elapsed Time: 41.1866\n",
      "\n",
      "Epoch: 4/250, Loss: 4.7048, Bleu: 0.01077, Elapsed: 114.47 secpsed: 114.47 sec\n",
      "Epoch: 4/250, Loss: 5.0847, Bleu: 0.00001, Elapsed Time: 41.4376\n",
      "\n",
      "Epoch: 5/250, Loss: 4.6804, Bleu: 0.01223, Elapsed: 114.66 secpsed: 114.66 sec\n",
      "Epoch: 5/250, Loss: 5.3549, Bleu: 0.00001, Elapsed Time: 41.6857\n",
      "\n",
      "Epoch: 6/250, Loss: 4.6612, Bleu: 0.00932, Elapsed: 114.30 secpsed: 114.30 sec\n",
      "Epoch: 6/250, Loss: 4.5372, Bleu: 0.00001, Elapsed Time: 41.1163\n",
      "\n",
      "Epoch: 7/250, Loss: 4.6435, Bleu: 0.00855, Elapsed: 114.76 secpsed: 114.76 sec\n",
      "Epoch: 7/250, Loss: 4.8765, Bleu: 0.00001, Elapsed Time: 41.2892\n",
      "\n",
      "Epoch: 8/250, Loss: 4.6283, Bleu: 0.00930, Elapsed: 114.50 secpsed: 114.50 sec\n",
      "Epoch: 8/250, Loss: 4.8053, Bleu: 0.00000, Elapsed Time: 41.1285\n",
      "\n",
      "Epoch: 9/250, Loss: 4.6156, Bleu: 0.01080, Elapsed: 114.49 secpsed: 114.49 sec\n",
      "Epoch: 9/250, Loss: 4.9183, Bleu: 0.00000, Elapsed Time: 50.8219\n",
      "\n",
      "Epoch: 10/250, Loss: 4.6006, Bleu: 0.01072, Elapsed: 114.71 secpsed: 114.71 sec\n",
      "Epoch: 10/250, Loss: 5.0722, Bleu: 0.00000, Elapsed Time: 53.7470\n",
      "\n",
      "Epoch: 11/250, Loss: 4.5857, Bleu: 0.01035, Elapsed: 114.83 secpsed: 114.83 sec\n",
      "Epoch: 11/250, Loss: 4.9077, Bleu: 0.00000, Elapsed Time: 48.8930\n",
      "\n",
      "Epoch: 12/250, Loss: 4.5702, Bleu: 0.01111, Elapsed: 114.64 secpsed: 114.64 sec\n",
      "Epoch: 12/250, Loss: 4.6632, Bleu: 0.00000, Elapsed Time: 62.3382\n",
      "\n",
      "Epoch: 13/250, Loss: 4.5538, Bleu: 0.01089, Elapsed: 114.70 secpsed: 114.70 sec\n",
      "Epoch: 13/250, Loss: 5.1167, Bleu: 0.00000, Elapsed Time: 60.3047\n",
      "\n",
      "Epoch: 14/250, Loss: 4.5337, Bleu: 0.01476, Elapsed: 114.81 secpsed: 114.81 sec\n",
      "Epoch: 14/250, Loss: 4.8408, Bleu: 0.00000, Elapsed Time: 69.0295\n",
      "\n",
      "Epoch: 15/250, Loss: 4.5179, Bleu: 0.01132, Elapsed: 114.80 secpsed: 114.80 sec\n",
      "Epoch: 15/250, Loss: 5.1302, Bleu: 0.00000, Elapsed Time: 71.8704\n",
      "\n",
      "Epoch: 16/250, Loss: 4.4993, Bleu: 0.01354, Elapsed: 114.57 secpsed: 114.57 sec\n",
      "Epoch: 16/250, Loss: 5.0084, Bleu: 0.00000, Elapsed Time: 67.9076\n",
      "\n",
      "Epoch: 17/250, Loss: 4.4807, Bleu: 0.01207, Elapsed: 114.61 secpsed: 114.61 sec\n",
      "Epoch: 17/250, Loss: 5.2171, Bleu: 0.00000, Elapsed Time: 65.3143\n",
      "\n",
      "Epoch: 18/250, Loss: 4.4604, Bleu: 0.01272, Elapsed: 114.98 secpsed: 114.98 sec\n",
      "Epoch: 18/250, Loss: 4.9097, Bleu: 0.00000, Elapsed Time: 74.8458\n",
      "\n",
      "Epoch: 19/250, Loss: 4.4384, Bleu: 0.01520, Elapsed: 114.80 secpsed: 114.80 sec\n",
      "Epoch: 19/250, Loss: 5.0636, Bleu: 0.00000, Elapsed Time: 71.9185\n",
      "\n",
      "Epoch: 20/250, Loss: 4.4178, Bleu: 0.01540, Elapsed: 114.74 secpsed: 114.74 sec\n",
      "Epoch: 20/250, Loss: 5.0147, Bleu: 0.00000, Elapsed Time: 75.4647\n",
      "\n",
      "Epoch: 21/250, Loss: 4.3939, Bleu: 0.01745, Elapsed: 114.67 secpsed: 114.67 sec\n",
      "Epoch: 21/250, Loss: 4.9218, Bleu: 0.00000, Elapsed Time: 77.5261\n",
      "\n",
      "Epoch: 22/250, Loss: 4.3699, Bleu: 0.01464, Elapsed: 114.63 secpsed: 114.63 sec\n",
      "Epoch: 22/250, Loss: 5.3833, Bleu: 0.00000, Elapsed Time: 77.0141\n",
      "\n",
      "Epoch: 23/250, Loss: 4.3439, Bleu: 0.01893, Elapsed: 114.91 secpsed: 114.91 sec\n",
      "Epoch: 23/250, Loss: 5.5501, Bleu: 0.00000, Elapsed Time: 77.9744\n",
      "\n",
      "Epoch: 24/250, Loss: 4.3157, Bleu: 0.01680, Elapsed: 114.92 secpsed: 114.92 sec\n",
      "Epoch: 24/250, Loss: 5.2935, Bleu: 0.00000, Elapsed Time: 78.0336\n",
      "\n",
      "Epoch: 25/250, Loss: 4.2889, Bleu: 0.01770, Elapsed: 114.89 secpsed: 114.89 sec\n",
      "Epoch: 25/250, Loss: 5.4784, Bleu: 0.00000, Elapsed Time: 77.6854\n",
      "\n",
      "Epoch: 26/250, Loss: 4.2585, Bleu: 0.02102, Elapsed: 115.14 secpsed: 115.14 sec\n",
      "Epoch: 26/250, Loss: 5.2936, Bleu: 0.00000, Elapsed Time: 77.8809\n",
      "\n",
      "Epoch: 27/250, Loss: 4.2265, Bleu: 0.02105, Elapsed: 115.03 secpsed: 115.03 sec\n",
      "Epoch: 27/250, Loss: 5.1441, Bleu: 0.00000, Elapsed Time: 78.0680\n",
      "\n",
      "Epoch: 28/250, Loss: 4.1937, Bleu: 0.02381, Elapsed: 114.94 secpsed: 114.94 sec\n",
      "Epoch: 28/250, Loss: 5.3144, Bleu: 0.00000, Elapsed Time: 77.3377\n",
      "\n",
      "Epoch: 29/250, Loss: 4.1586, Bleu: 0.02307, Elapsed: 115.17 secpsed: 115.17 sec\n",
      "Epoch: 29/250, Loss: 5.3393, Bleu: 0.00000, Elapsed Time: 77.0367\n",
      "\n",
      "Epoch: 30/250, Loss: 4.1206, Bleu: 0.02895, Elapsed: 115.07 secpsed: 115.07 sec\n",
      "Epoch: 30/250, Loss: 5.6720, Bleu: 0.00000, Elapsed Time: 77.0394\n",
      "\n",
      "Epoch: 31/250, Loss: 4.0837, Bleu: 0.03349, Elapsed: 115.28 secpsed: 115.28 sec\n",
      "Epoch: 31/250, Loss: 5.3456, Bleu: 0.00000, Elapsed Time: 77.3693\n",
      "\n",
      "Epoch: 32/250, Loss: 4.0445, Bleu: 0.03017, Elapsed: 115.12 secpsed: 115.12 sec\n",
      "Epoch: 32/250, Loss: 5.4707, Bleu: 0.00000, Elapsed Time: 77.3091\n",
      "\n",
      "Epoch: 33/250, Loss: 4.0045, Bleu: 0.03393, Elapsed: 115.07 secpsed: 115.07 sec\n",
      "Epoch: 33/250, Loss: 5.4347, Bleu: 0.00000, Elapsed Time: 77.7536\n",
      "\n",
      "Epoch: 34/250, Loss: 3.9637, Bleu: 0.04186, Elapsed: 115.12 secpsed: 115.12 sec\n",
      "Epoch: 34/250, Loss: 5.0824, Bleu: 0.00000, Elapsed Time: 76.7619\n",
      "\n",
      "Epoch: 35/250, Loss: 3.9163, Bleu: 0.04634, Elapsed: 115.20 secpsed: 115.20 sec\n",
      "Epoch: 35/250, Loss: 5.5522, Bleu: 0.00000, Elapsed Time: 78.4765\n",
      "\n",
      "Epoch: 36/250, Loss: 3.8725, Bleu: 0.04523, Elapsed: 115.19 secpsed: 115.19 sec\n",
      "Epoch: 36/250, Loss: 5.8436, Bleu: 0.00000, Elapsed Time: 77.5431\n",
      "\n",
      "Epoch: 37/250, Loss: 3.8265, Bleu: 0.05140, Elapsed: 115.22 secpsed: 115.22 sec\n",
      "Epoch: 37/250, Loss: 5.3198, Bleu: 0.00000, Elapsed Time: 74.1807\n",
      "\n",
      "Epoch: 38/250, Loss: 3.7793, Bleu: 0.06379, Elapsed: 114.82 secpsed: 114.82 sec\n",
      "Epoch: 38/250, Loss: 5.9390, Bleu: 0.00000, Elapsed Time: 75.1050\n",
      "\n",
      "Epoch: 39/250, Loss: 3.7307, Bleu: 0.07506, Elapsed: 115.13 secpsed: 115.13 sec\n",
      "Epoch: 39/250, Loss: 5.2983, Bleu: 0.00000, Elapsed Time: 73.8342\n",
      "\n",
      "Epoch: 40/250, Loss: 3.6789, Bleu: 0.08573, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 40/250, Loss: 5.4671, Bleu: 0.00000, Elapsed Time: 75.0624\n",
      "\n",
      "Epoch: 41/250, Loss: 3.6290, Bleu: 0.09226, Elapsed: 115.34 secpsed: 115.34 sec\n",
      "Epoch: 41/250, Loss: 5.4797, Bleu: 0.00000, Elapsed Time: 71.1748\n",
      "\n",
      "Epoch: 42/250, Loss: 3.5767, Bleu: 0.10693, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 42/250, Loss: 5.9713, Bleu: 0.00000, Elapsed Time: 73.3963\n",
      "\n",
      "Epoch: 43/250, Loss: 3.5253, Bleu: 0.10807, Elapsed: 115.49 secpsed: 115.49 sec\n",
      "Epoch: 43/250, Loss: 6.0626, Bleu: 0.00000, Elapsed Time: 74.3421\n",
      "\n",
      "Epoch: 44/250, Loss: 3.4809, Bleu: 0.12122, Elapsed: 115.18 secpsed: 115.18 sec\n",
      "Epoch: 44/250, Loss: 5.6191, Bleu: 0.00000, Elapsed Time: 68.6359\n",
      "\n",
      "Epoch: 45/250, Loss: 3.4341, Bleu: 0.13187, Elapsed: 115.45 secpsed: 115.45 sec\n",
      "Epoch: 45/250, Loss: 6.2407, Bleu: 0.00000, Elapsed Time: 69.0665\n",
      "\n",
      "Epoch: 46/250, Loss: 3.3858, Bleu: 0.14871, Elapsed: 115.30 secpsed: 115.30 sec\n",
      "Epoch: 46/250, Loss: 6.1728, Bleu: 0.00000, Elapsed Time: 68.8808\n",
      "\n",
      "Epoch: 47/250, Loss: 3.3361, Bleu: 0.15755, Elapsed: 115.02 secpsed: 115.02 sec\n",
      "Epoch: 47/250, Loss: 6.2036, Bleu: 0.00000, Elapsed Time: 69.0266\n",
      "\n",
      "Epoch: 48/250, Loss: 3.2906, Bleu: 0.16037, Elapsed: 115.15 secpsed: 115.15 sec\n",
      "Epoch: 48/250, Loss: 6.4223, Bleu: 0.00000, Elapsed Time: 70.4152\n",
      "\n",
      "Epoch: 49/250, Loss: 3.2394, Bleu: 0.18715, Elapsed: 115.15 secpsed: 115.15 sec\n",
      "Epoch: 49/250, Loss: 6.5102, Bleu: 0.00000, Elapsed Time: 66.2129\n",
      "\n",
      "Epoch: 50/250, Loss: 3.1956, Bleu: 0.19277, Elapsed: 115.33 secpsed: 115.33 sec\n",
      "Epoch: 50/250, Loss: 6.2578, Bleu: 0.00000, Elapsed Time: 70.7771\n",
      "\n",
      "Epoch: 51/250, Loss: 3.1488, Bleu: 0.20050, Elapsed: 115.44 secpsed: 115.44 sec\n",
      "Epoch: 51/250, Loss: 6.3741, Bleu: 0.00000, Elapsed Time: 61.9014\n",
      "\n",
      "Epoch: 52/250, Loss: 3.1091, Bleu: 0.21814, Elapsed: 115.34 secpsed: 115.34 sec\n",
      "Epoch: 52/250, Loss: 6.5547, Bleu: 0.00000, Elapsed Time: 65.5924\n",
      "\n",
      "Epoch: 53/250, Loss: 3.0568, Bleu: 0.21566, Elapsed: 115.36 secpsed: 115.36 sec\n",
      "Epoch: 53/250, Loss: 6.7392, Bleu: 0.00000, Elapsed Time: 63.2803\n",
      "\n",
      "Epoch: 54/250, Loss: 3.0131, Bleu: 0.24340, Elapsed: 115.21 secpsed: 115.21 sec\n",
      "Epoch: 54/250, Loss: 6.7917, Bleu: 0.00000, Elapsed Time: 67.1717\n",
      "\n",
      "Epoch: 55/250, Loss: 2.9667, Bleu: 0.24093, Elapsed: 115.05 secpsed: 115.05 sec\n",
      "Epoch: 55/250, Loss: 6.5297, Bleu: 0.00000, Elapsed Time: 63.3888\n",
      "\n",
      "Epoch: 56/250, Loss: 2.9165, Bleu: 0.23870, Elapsed: 115.18 secpsed: 115.18 sec\n",
      "Epoch: 56/250, Loss: 7.3434, Bleu: 0.00000, Elapsed Time: 60.6535\n",
      "\n",
      "Epoch: 57/250, Loss: 2.8782, Bleu: 0.25081, Elapsed: 115.27 secpsed: 115.27 sec\n",
      "Epoch: 57/250, Loss: 7.1609, Bleu: 0.00000, Elapsed Time: 63.3457\n",
      "\n",
      "Epoch: 58/250, Loss: 2.8324, Bleu: 0.24707, Elapsed: 115.40 secpsed: 115.40 sec\n",
      "Epoch: 58/250, Loss: 6.7517, Bleu: 0.00000, Elapsed Time: 59.9914\n",
      "\n",
      "Epoch: 59/250, Loss: 2.7857, Bleu: 0.29726, Elapsed: 115.27 secpsed: 115.27 sec\n",
      "Epoch: 59/250, Loss: 7.3030, Bleu: 0.00000, Elapsed Time: 61.1584\n",
      "\n",
      "Epoch: 60/250, Loss: 2.7471, Bleu: 0.27731, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 60/250, Loss: 7.5979, Bleu: 0.00000, Elapsed Time: 62.3472\n",
      "\n",
      "Epoch: 61/250, Loss: 2.6975, Bleu: 0.28945, Elapsed: 115.29 secpsed: 115.29 sec\n",
      "Epoch: 61/250, Loss: 7.0080, Bleu: 0.00000, Elapsed Time: 55.8994\n",
      "\n",
      "Epoch: 62/250, Loss: 2.6601, Bleu: 0.29334, Elapsed: 115.45 secpsed: 115.45 sec\n",
      "Epoch: 62/250, Loss: 7.4910, Bleu: 0.00000, Elapsed Time: 56.8895\n",
      "\n",
      "Epoch: 63/250, Loss: 2.6177, Bleu: 0.32438, Elapsed: 115.57 secpsed: 115.57 sec\n",
      "Epoch: 63/250, Loss: 7.0758, Bleu: 0.00000, Elapsed Time: 58.4296\n",
      "\n",
      "Epoch: 64/250, Loss: 2.5719, Bleu: 0.32705, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 64/250, Loss: 7.0387, Bleu: 0.00000, Elapsed Time: 60.7385\n",
      "\n",
      "Epoch: 65/250, Loss: 2.5222, Bleu: 0.34347, Elapsed: 115.44 secpsed: 115.44 sec\n",
      "Epoch: 65/250, Loss: 7.0606, Bleu: 0.00000, Elapsed Time: 55.5347\n",
      "\n",
      "Epoch: 66/250, Loss: 2.4822, Bleu: 0.34522, Elapsed: 115.40 secpsed: 115.40 sec\n",
      "Epoch: 66/250, Loss: 7.7478, Bleu: 0.00000, Elapsed Time: 58.9670\n",
      "\n",
      "Epoch: 67/250, Loss: 2.4359, Bleu: 0.36950, Elapsed: 115.49 secpsed: 115.49 sec\n",
      "Epoch: 67/250, Loss: 7.3761, Bleu: 0.00000, Elapsed Time: 58.6334\n",
      "\n",
      "Epoch: 68/250, Loss: 2.3982, Bleu: 0.37009, Elapsed: 115.56 secpsed: 115.56 sec\n",
      "Epoch: 68/250, Loss: 7.5167, Bleu: 0.00000, Elapsed Time: 58.0430\n",
      "\n",
      "Epoch: 69/250, Loss: 2.3568, Bleu: 0.38772, Elapsed: 115.64 secpsed: 115.64 sec\n",
      "Epoch: 69/250, Loss: 7.8388, Bleu: 0.00000, Elapsed Time: 56.1809\n",
      "\n",
      "Epoch: 70/250, Loss: 2.3051, Bleu: 0.37012, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 70/250, Loss: 7.4869, Bleu: 0.00000, Elapsed Time: 59.3021\n",
      "\n",
      "Epoch: 71/250, Loss: 2.2547, Bleu: 0.40073, Elapsed: 115.47 secpsed: 115.47 sec\n",
      "Epoch: 71/250, Loss: 8.1427, Bleu: 0.00000, Elapsed Time: 60.5106\n",
      "\n",
      "Epoch: 72/250, Loss: 2.2169, Bleu: 0.38813, Elapsed: 115.48 secpsed: 115.48 sec\n",
      "Epoch: 72/250, Loss: 7.8133, Bleu: 0.00000, Elapsed Time: 58.6491\n",
      "\n",
      "Epoch: 73/250, Loss: 2.1780, Bleu: 0.43100, Elapsed: 115.40 secpsed: 115.40 sec\n",
      "Epoch: 73/250, Loss: 8.2349, Bleu: 0.00000, Elapsed Time: 56.8798\n",
      "\n",
      "Epoch: 74/250, Loss: 2.1308, Bleu: 0.44680, Elapsed: 115.31 secpsed: 115.31 sec\n",
      "Epoch: 74/250, Loss: 8.2117, Bleu: 0.00000, Elapsed Time: 59.5307\n",
      "\n",
      "Epoch: 75/250, Loss: 2.0924, Bleu: 0.41447, Elapsed: 115.24 secpsed: 115.24 sec\n",
      "Epoch: 75/250, Loss: 7.7434, Bleu: 0.00000, Elapsed Time: 55.5221\n",
      "\n",
      "Epoch: 76/250, Loss: 2.0483, Bleu: 0.47130, Elapsed: 115.40 secpsed: 115.40 sec\n",
      "Epoch: 76/250, Loss: 8.7667, Bleu: 0.00000, Elapsed Time: 58.5234\n",
      "\n",
      "Epoch: 77/250, Loss: 1.9991, Bleu: 0.44911, Elapsed: 115.55 secpsed: 115.55 sec\n",
      "Epoch: 77/250, Loss: 7.9841, Bleu: 0.00000, Elapsed Time: 54.9863\n",
      "\n",
      "Epoch: 78/250, Loss: 1.9555, Bleu: 0.46822, Elapsed: 115.32 secpsed: 115.32 sec\n",
      "Epoch: 78/250, Loss: 8.3404, Bleu: 0.00000, Elapsed Time: 56.4424\n",
      "\n",
      "Epoch: 79/250, Loss: 1.9151, Bleu: 0.48914, Elapsed: 115.36 secpsed: 115.36 sec\n",
      "Epoch: 79/250, Loss: 8.9032, Bleu: 0.00000, Elapsed Time: 53.4836\n",
      "\n",
      "Epoch: 80/250, Loss: 1.8873, Bleu: 0.49487, Elapsed: 115.20 secpsed: 115.20 sec\n",
      "Epoch: 80/250, Loss: 8.3375, Bleu: 0.00000, Elapsed Time: 56.1674\n",
      "\n",
      "Epoch: 81/250, Loss: 1.8619, Bleu: 0.49457, Elapsed: 115.42 secpsed: 115.42 sec\n",
      "Epoch: 81/250, Loss: 8.4502, Bleu: 0.00000, Elapsed Time: 55.4151\n",
      "\n",
      "Epoch: 82/250, Loss: 1.7852, Bleu: 0.52096, Elapsed: 115.40 secpsed: 115.40 sec\n",
      "Epoch: 82/250, Loss: 8.1865, Bleu: 0.00000, Elapsed Time: 55.1747\n",
      "\n",
      "Epoch: 83/250, Loss: 1.7431, Bleu: 0.53513, Elapsed: 115.58 secpsed: 115.58 sec\n",
      "Epoch: 83/250, Loss: 8.7957, Bleu: 0.00000, Elapsed Time: 59.2947\n",
      "\n",
      "Epoch: 84/250, Loss: 1.7003, Bleu: 0.54210, Elapsed: 115.48 secpsed: 115.48 sec\n",
      "Epoch: 84/250, Loss: 8.7335, Bleu: 0.00000, Elapsed Time: 58.1804\n",
      "\n",
      "Epoch: 85/250, Loss: 1.6556, Bleu: 0.57257, Elapsed: 115.64 secpsed: 115.64 sec\n",
      "Epoch: 85/250, Loss: 8.9792, Bleu: 0.00000, Elapsed Time: 58.7436\n",
      "\n",
      "Epoch: 86/250, Loss: 1.6182, Bleu: 0.55011, Elapsed: 115.33 secpsed: 115.33 sec\n",
      "Epoch: 86/250, Loss: 9.0593, Bleu: 0.00000, Elapsed Time: 55.7265\n",
      "\n",
      "Epoch: 87/250, Loss: 1.5847, Bleu: 0.58487, Elapsed: 115.62 secpsed: 115.62 sec\n",
      "Epoch: 87/250, Loss: 8.9475, Bleu: 0.00000, Elapsed Time: 56.7478\n",
      "\n",
      "Epoch: 88/250, Loss: 1.5405, Bleu: 0.55658, Elapsed: 116.11 secpsed: 116.11 sec\n",
      "Epoch: 88/250, Loss: 9.1361, Bleu: 0.00000, Elapsed Time: 55.1789\n",
      "\n",
      "Epoch: 89/250, Loss: 1.5104, Bleu: 0.59415, Elapsed: 115.86 secpsed: 115.86 sec\n",
      "Epoch: 89/250, Loss: 9.1828, Bleu: 0.00000, Elapsed Time: 55.0606\n",
      "\n",
      "Epoch: 90/250, Loss: 1.4647, Bleu: 0.59234, Elapsed: 115.74 secpsed: 115.74 sec\n",
      "Epoch: 90/250, Loss: 8.7288, Bleu: 0.00000, Elapsed Time: 57.7924\n",
      "\n",
      "Epoch: 91/250, Loss: 1.4324, Bleu: 0.59070, Elapsed: 115.87 secpsed: 115.87 sec\n",
      "Epoch: 91/250, Loss: 8.3151, Bleu: 0.00000, Elapsed Time: 58.4807\n",
      "\n",
      "Epoch: 92/250, Loss: 1.3804, Bleu: 0.62372, Elapsed: 115.68 secpsed: 115.68 sec\n",
      "Epoch: 92/250, Loss: 8.4380, Bleu: 0.00000, Elapsed Time: 56.3297\n",
      "\n",
      "Epoch: 93/250, Loss: 1.3494, Bleu: 0.63053, Elapsed: 115.83 secpsed: 115.83 sec\n",
      "Epoch: 93/250, Loss: 9.2938, Bleu: 0.00000, Elapsed Time: 57.2407\n",
      "\n",
      "Epoch: 94/250, Loss: 1.3176, Bleu: 0.63640, Elapsed: 115.99 secpsed: 115.99 sec\n",
      "Epoch: 94/250, Loss: 9.3738, Bleu: 0.00000, Elapsed Time: 53.8762\n",
      "\n",
      "Epoch: 95/250, Loss: 1.2935, Bleu: 0.62496, Elapsed: 116.43 secpsed: 116.43 sec\n",
      "Epoch: 95/250, Loss: 10.2753, Bleu: 0.00000, Elapsed Time: 53.4704\n",
      "\n",
      "Epoch: 96/250, Loss: 1.2488, Bleu: 0.64936, Elapsed: 116.51 secpsed: 116.51 sec\n",
      "Epoch: 96/250, Loss: 10.0102, Bleu: 0.00000, Elapsed Time: 56.4879\n",
      "\n",
      "Epoch: 97/250, Loss: 1.2244, Bleu: 0.67696, Elapsed: 116.49 secpsed: 116.49 sec\n",
      "Epoch: 97/250, Loss: 8.4123, Bleu: 0.00000, Elapsed Time: 55.3516\n",
      "\n",
      "Epoch: 98/250, Loss: 1.1837, Bleu: 0.66047, Elapsed: 116.38 secpsed: 116.38 sec\n",
      "Epoch: 98/250, Loss: 9.8806, Bleu: 0.00000, Elapsed Time: 59.8922\n",
      "\n",
      "Epoch: 99/250, Loss: 1.1453, Bleu: 0.68028, Elapsed: 116.53 secpsed: 116.53 sec\n",
      "Epoch: 99/250, Loss: 10.1441, Bleu: 0.00000, Elapsed Time: 58.5137\n",
      "\n",
      "Epoch: 100/250, Loss: 1.1078, Bleu: 0.69209, Elapsed: 116.52 secpsed: 116.52 sec\n",
      "Epoch: 100/250, Loss: 9.3760, Bleu: 0.00000, Elapsed Time: 54.0712\n",
      "\n",
      "Epoch: 101/250, Loss: 1.0807, Bleu: 0.68035, Elapsed: 116.37 secpsed: 116.37 sec\n",
      "Epoch: 101/250, Loss: 9.3702, Bleu: 0.00000, Elapsed Time: 59.2043\n",
      "\n",
      "Epoch: 102/250, Loss: 1.0533, Bleu: 0.70843, Elapsed: 116.37 secpsed: 116.37 sec\n",
      "Epoch: 102/250, Loss: 10.3375, Bleu: 0.00000, Elapsed Time: 56.5580\n",
      "\n",
      "Epoch: 103/250, Loss: 1.0173, Bleu: 0.71547, Elapsed: 116.52 secpsed: 116.52 sec\n",
      "Epoch: 103/250, Loss: 10.2342, Bleu: 0.00000, Elapsed Time: 59.1500\n",
      "\n",
      "Epoch: 104/250, Loss: 0.9888, Bleu: 0.72606, Elapsed: 116.62 secpsed: 116.62 sec\n",
      "Epoch: 104/250, Loss: 9.9266, Bleu: 0.00000, Elapsed Time: 60.4607\n",
      "\n",
      "Epoch: 105/250, Loss: 0.9756, Bleu: 0.71192, Elapsed: 116.60 secpsed: 116.60 sec\n",
      "Epoch: 105/250, Loss: 10.5088, Bleu: 0.00000, Elapsed Time: 55.3877\n",
      "\n",
      "Epoch: 106/250, Loss: 0.9472, Bleu: 0.72898, Elapsed: 116.55 secpsed: 116.55 sec\n",
      "Epoch: 106/250, Loss: 10.2360, Bleu: 0.00000, Elapsed Time: 55.8695\n",
      "\n",
      "Epoch: 107/250, Loss: 0.9176, Bleu: 0.71814, Elapsed: 116.57 secpsed: 116.57 sec\n",
      "Epoch: 107/250, Loss: 9.8920, Bleu: 0.00000, Elapsed Time: 56.3719\n",
      "\n",
      "Epoch: 108/250, Loss: 0.8850, Bleu: 0.75116, Elapsed: 116.52 secpsed: 116.52 sec\n",
      "Epoch: 108/250, Loss: 9.5474, Bleu: 0.00000, Elapsed Time: 57.8252\n",
      "\n",
      "Epoch: 109/250, Loss: 0.8421, Bleu: 0.78083, Elapsed: 116.12 secpsed: 116.12 sec\n",
      "Epoch: 109/250, Loss: 10.2512, Bleu: 0.00000, Elapsed Time: 58.1630\n",
      "\n",
      "Epoch: 110/250, Loss: 0.8072, Bleu: 0.78027, Elapsed: 116.26 secpsed: 116.26 sec\n",
      "Epoch: 110/250, Loss: 10.5222, Bleu: 0.00000, Elapsed Time: 57.3672\n",
      "\n",
      "Epoch: 111/250, Loss: 0.7919, Bleu: 0.75845, Elapsed: 116.19 secpsed: 116.19 sec\n",
      "Epoch: 111/250, Loss: 10.2074, Bleu: 0.00000, Elapsed Time: 55.2133\n",
      "\n",
      "Epoch: 112/250, Loss: 0.7899, Bleu: 0.74766, Elapsed: 116.19 secpsed: 116.19 sec\n",
      "Epoch: 112/250, Loss: 10.9759, Bleu: 0.00000, Elapsed Time: 59.4843\n",
      "\n",
      "Epoch: 113/250, Loss: 0.7605, Bleu: 0.77130, Elapsed: 116.24 secpsed: 116.24 sec\n",
      "Epoch: 113/250, Loss: 11.0308, Bleu: 0.00000, Elapsed Time: 57.8758\n",
      "\n",
      "Epoch: 114/250, Loss: 0.7374, Bleu: 0.80355, Elapsed: 116.29 secpsed: 116.29 sec\n",
      "Epoch: 114/250, Loss: 10.6882, Bleu: 0.00000, Elapsed Time: 57.4346\n",
      "\n",
      "Epoch: 115/250, Loss: 0.7136, Bleu: 0.77917, Elapsed: 116.20 secpsed: 116.20 sec\n",
      "Epoch: 115/250, Loss: 11.1380, Bleu: 0.00000, Elapsed Time: 57.7616\n",
      "\n",
      "Epoch: 116/250, Loss: 0.6843, Bleu: 0.78796, Elapsed: 116.12 secpsed: 116.12 sec\n",
      "Epoch: 116/250, Loss: 10.0647, Bleu: 0.00000, Elapsed Time: 58.7636\n",
      "\n",
      "Epoch: 117/250, Loss: 0.6686, Bleu: 0.80449, Elapsed: 116.37 secpsed: 116.37 sec\n",
      "Epoch: 117/250, Loss: 12.0897, Bleu: 0.00000, Elapsed Time: 58.4440\n",
      "\n",
      "Epoch: 118/250, Loss: 0.6419, Bleu: 0.80955, Elapsed: 116.28 secpsed: 116.28 sec\n",
      "Epoch: 118/250, Loss: 10.4815, Bleu: 0.00000, Elapsed Time: 62.8691\n",
      "\n",
      "Epoch: 119/250, Loss: 0.6398, Bleu: 0.81202, Elapsed: 116.34 secpsed: 116.34 sec\n",
      "Epoch: 119/250, Loss: 11.1545, Bleu: 0.00000, Elapsed Time: 59.0140\n",
      "\n",
      "Epoch: 120/250, Loss: 0.6017, Bleu: 0.82741, Elapsed: 116.38 secpsed: 116.38 sec\n",
      "Epoch: 120/250, Loss: 11.3776, Bleu: 0.00000, Elapsed Time: 58.5992\n",
      "\n",
      "Epoch: 121/250, Loss: 0.5812, Bleu: 0.81674, Elapsed: 116.38 secpsed: 116.38 sec\n",
      "Epoch: 121/250, Loss: 10.9140, Bleu: 0.00000, Elapsed Time: 56.0161\n",
      "\n",
      "Epoch: 122/250, Loss: 0.5599, Bleu: 0.83058, Elapsed: 116.31 secpsed: 116.31 sec\n",
      "Epoch: 122/250, Loss: 11.3934, Bleu: 0.00000, Elapsed Time: 58.0978\n",
      "\n",
      "Epoch: 123/250, Loss: 0.5342, Bleu: 0.84959, Elapsed: 116.45 secpsed: 116.45 sec\n",
      "Epoch: 123/250, Loss: 11.1861, Bleu: 0.00000, Elapsed Time: 57.3752\n",
      "\n",
      "Epoch: 124/250, Loss: 0.5283, Bleu: 0.86050, Elapsed: 116.39 secpsed: 116.39 sec\n",
      "Epoch: 124/250, Loss: 11.7877, Bleu: 0.00000, Elapsed Time: 59.4396\n",
      "\n",
      "Epoch: 125/250, Loss: 0.5400, Bleu: 0.85217, Elapsed: 116.19 secpsed: 116.19 sec\n",
      "Epoch: 125/250, Loss: 12.1101, Bleu: 0.00000, Elapsed Time: 60.9196\n",
      "\n",
      "Epoch: 126/250, Loss: 0.5300, Bleu: 0.84870, Elapsed: 116.32 secpsed: 116.32 sec\n",
      "Epoch: 126/250, Loss: 11.3566, Bleu: 0.00000, Elapsed Time: 58.5416\n",
      "\n",
      "Epoch: 127/250, Loss: 0.5110, Bleu: 0.86430, Elapsed: 116.28 secpsed: 116.28 sec\n",
      "Epoch: 127/250, Loss: 11.1355, Bleu: 0.00000, Elapsed Time: 60.2583\n",
      "\n",
      "Epoch: 128/250, Loss: 0.4704, Bleu: 0.86474, Elapsed: 116.18 secpsed: 116.18 sec\n",
      "Epoch: 128/250, Loss: 11.5535, Bleu: 0.00000, Elapsed Time: 59.3936\n",
      "\n",
      "Epoch: 129/250, Loss: 0.4405, Bleu: 0.87804, Elapsed: 116.33 secpsed: 116.33 sec\n",
      "Epoch: 129/250, Loss: 11.6240, Bleu: 0.00000, Elapsed Time: 57.4133\n",
      "\n",
      "Epoch: 130/250, Loss: 0.4190, Bleu: 0.87736, Elapsed: 116.51 secpsed: 116.51 sec\n",
      "Epoch: 130/250, Loss: 11.8492, Bleu: 0.00000, Elapsed Time: 59.7346\n",
      "\n",
      "Epoch: 131/250, Loss: 0.3995, Bleu: 0.89294, Elapsed: 116.40 secpsed: 116.40 sec\n",
      "Epoch: 131/250, Loss: 11.3609, Bleu: 0.00000, Elapsed Time: 61.5864\n",
      "\n",
      "Epoch: 132/250, Loss: 0.3950, Bleu: 0.88774, Elapsed: 116.20 secpsed: 116.20 sec\n",
      "Epoch: 132/250, Loss: 12.2730, Bleu: 0.00000, Elapsed Time: 63.9902\n",
      "\n",
      "Epoch: 133/250, Loss: 0.4074, Bleu: 0.87629, Elapsed: 116.06 secpsed: 116.06 sec\n",
      "Epoch: 133/250, Loss: 12.3951, Bleu: 0.00000, Elapsed Time: 60.5341\n",
      "\n",
      "Epoch: 134/250, Loss: 0.4193, Bleu: 0.87406, Elapsed: 116.23 secpsed: 116.23 sec\n",
      "Epoch: 134/250, Loss: 11.7347, Bleu: 0.00000, Elapsed Time: 58.8384\n",
      "\n",
      "Epoch: 135/250, Loss: 0.4060, Bleu: 0.87917, Elapsed: 116.24 secpsed: 116.24 sec\n",
      "Epoch: 135/250, Loss: 12.1487, Bleu: 0.00000, Elapsed Time: 61.7385\n",
      "\n",
      "Epoch: 136/250, Loss: 0.3846, Bleu: 0.87731, Elapsed: 116.16 secpsed: 116.16 sec\n",
      "Epoch: 136/250, Loss: 12.3170, Bleu: 0.00000, Elapsed Time: 62.7899\n",
      "\n",
      "Epoch: 137/250, Loss: 0.3533, Bleu: 0.90297, Elapsed: 116.04 secpsed: 116.04 sec\n",
      "Epoch: 137/250, Loss: 11.6679, Bleu: 0.00000, Elapsed Time: 59.1713\n",
      "\n",
      "Epoch: 138/250, Loss: 0.3199, Bleu: 0.90524, Elapsed: 116.24 secpsed: 116.24 sec\n",
      "Epoch: 138/250, Loss: 11.6747, Bleu: 0.00000, Elapsed Time: 61.2876\n",
      "\n",
      "Epoch: 139/250, Loss: 0.3048, Bleu: 0.92856, Elapsed: 116.01 secpsed: 116.01 sec\n",
      "Epoch: 139/250, Loss: 11.6850, Bleu: 0.00000, Elapsed Time: 59.1511\n",
      "\n",
      "Epoch: 140/250, Loss: 0.2918, Bleu: 0.92884, Elapsed: 116.21 secpsed: 116.21 sec\n",
      "Epoch: 140/250, Loss: 13.1230, Bleu: 0.00000, Elapsed Time: 58.9845\n",
      "\n",
      "Epoch: 141/250, Loss: 0.3023, Bleu: 0.92166, Elapsed: 116.06 secpsed: 116.06 sec\n",
      "Epoch: 141/250, Loss: 12.9266, Bleu: 0.00000, Elapsed Time: 58.4923\n",
      "\n",
      "Epoch: 142/250, Loss: 0.3317, Bleu: 0.89085, Elapsed: 115.89 secpsed: 115.89 sec\n",
      "Epoch: 142/250, Loss: 12.3025, Bleu: 0.00000, Elapsed Time: 60.6613\n",
      "\n",
      "Epoch: 143/250, Loss: 0.3575, Bleu: 0.88334, Elapsed: 116.28 secpsed: 116.28 sec\n",
      "Epoch: 143/250, Loss: 12.3445, Bleu: 0.00000, Elapsed Time: 60.1331\n",
      "\n",
      "Epoch: 144/250, Loss: 0.3410, Bleu: 0.88720, Elapsed: 116.21 secpsed: 116.21 sec\n",
      "Epoch: 144/250, Loss: 12.5570, Bleu: 0.00000, Elapsed Time: 60.9850\n",
      "\n",
      "Epoch: 145/250, Loss: 0.3026, Bleu: 0.90475, Elapsed: 116.21 secpsed: 116.21 sec\n",
      "Epoch: 145/250, Loss: 12.0281, Bleu: 0.00000, Elapsed Time: 61.3969\n",
      "\n",
      "Epoch: 146/250, Loss: 0.2784, Bleu: 0.92354, Elapsed: 116.30 secpsed: 116.30 sec\n",
      "Epoch: 146/250, Loss: 12.6092, Bleu: 0.00000, Elapsed Time: 60.7146\n",
      "\n",
      "Epoch: 147/250, Loss: 0.2401, Bleu: 0.92893, Elapsed: 116.11 secpsed: 116.11 sec\n",
      "Epoch: 147/250, Loss: 12.9121, Bleu: 0.00000, Elapsed Time: 67.2201\n",
      "\n",
      "Epoch: 148/250, Loss: 0.2119, Bleu: 0.93204, Elapsed: 116.05 secpsed: 116.05 sec\n",
      "Epoch: 148/250, Loss: 13.0680, Bleu: 0.00000, Elapsed Time: 58.1425\n",
      "\n",
      "Epoch: 149/250, Loss: 0.1933, Bleu: 0.95858, Elapsed: 116.41 secpsed: 116.41 sec\n",
      "Epoch: 149/250, Loss: 12.6952, Bleu: 0.00000, Elapsed Time: 57.1974\n",
      "\n",
      "Epoch: 150/250, Loss: 0.1938, Bleu: 0.93742, Elapsed: 115.97 secpsed: 115.97 sec\n",
      "Epoch: 150/250, Loss: 12.4829, Bleu: 0.00000, Elapsed Time: 61.6821\n",
      "\n",
      "Epoch: 151/250, Loss: 0.2551, Bleu: 0.93790, Elapsed: 116.19 secpsed: 116.19 sec\n",
      "Epoch: 151/250, Loss: 12.2442, Bleu: 0.00000, Elapsed Time: 60.3393\n",
      "\n",
      "Epoch: 152/250, Loss: 0.3386, Bleu: 0.90785, Elapsed: 116.28 secpsed: 116.28 sec\n",
      "Epoch: 152/250, Loss: 12.7603, Bleu: 0.00000, Elapsed Time: 59.9572\n",
      "\n",
      "Epoch: 153/250, Loss: 0.3821, Bleu: 0.85665, Elapsed: 116.32 secpsed: 116.32 sec\n",
      "Epoch: 153/250, Loss: 12.6309, Bleu: 0.00000, Elapsed Time: 58.5017\n",
      "\n",
      "Epoch: 154/250, Loss: 0.2912, Bleu: 0.91016, Elapsed: 116.17 secpsed: 116.17 sec\n",
      "Epoch: 154/250, Loss: 14.0107, Bleu: 0.00000, Elapsed Time: 60.3002\n",
      "\n",
      "Epoch: 155/250, Loss: 0.1961, Bleu: 0.94566, Elapsed: 116.22 secpsed: 116.22 sec\n",
      "Epoch: 155/250, Loss: 12.8552, Bleu: 0.00000, Elapsed Time: 63.7543\n",
      "\n",
      "Epoch: 156/250, Loss: 0.1450, Bleu: 0.96729, Elapsed: 116.40 secpsed: 116.40 sec\n",
      "Epoch: 156/250, Loss: 13.3674, Bleu: 0.00000, Elapsed Time: 60.8541\n",
      "\n",
      "Epoch: 157/250, Loss: 0.1180, Bleu: 0.97090, Elapsed: 116.23 secpsed: 116.23 sec\n",
      "Epoch: 157/250, Loss: 13.3506, Bleu: 0.00000, Elapsed Time: 61.0814\n",
      "\n",
      "Epoch: 158/250, Loss: 0.1058, Bleu: 0.98282, Elapsed: 116.28 secpsed: 116.28 sec\n",
      "Epoch: 158/250, Loss: 12.2786, Bleu: 0.00000, Elapsed Time: 63.9321\n",
      "\n",
      "Epoch: 159/250, Loss: 0.1003, Bleu: 0.97347, Elapsed: 116.23 secpsed: 116.23 sec\n",
      "Epoch: 159/250, Loss: 13.3168, Bleu: 0.00000, Elapsed Time: 62.7568\n",
      "\n",
      "Epoch: 160/250, Loss: 0.1128, Bleu: 0.97481, Elapsed: 116.16 secpsed: 116.16 sec\n",
      "Epoch: 160/250, Loss: 13.0730, Bleu: 0.00000, Elapsed Time: 62.8624\n",
      "\n",
      "Epoch: 161/250, Loss: 0.2436, Bleu: 0.90969, Elapsed: 116.00 secpsed: 116.00 sec\n",
      "Epoch: 161/250, Loss: 12.9074, Bleu: 0.00000, Elapsed Time: 61.5651\n",
      "\n",
      "Epoch: 162/250, Loss: 0.7411, Bleu: 0.73762, Elapsed: 116.24 secpsed: 116.24 sec\n",
      "Epoch: 162/250, Loss: 13.0394, Bleu: 0.00000, Elapsed Time: 60.6300\n",
      "\n",
      "Epoch: 163/250, Loss: 0.4693, Bleu: 0.81881, Elapsed: 116.11 secpsed: 116.11 sec\n",
      "Epoch: 163/250, Loss: 13.7745, Bleu: 0.00000, Elapsed Time: 63.1637\n",
      "\n",
      "Epoch: 164/250, Loss: 0.2071, Bleu: 0.94264, Elapsed: 116.56 secpsed: 116.56 sec\n",
      "Epoch: 164/250, Loss: 12.6625, Bleu: 0.00000, Elapsed Time: 64.9623\n",
      "\n",
      "Epoch: 165/250, Loss: 0.1110, Bleu: 0.97339, Elapsed: 116.49 secpsed: 116.49 sec\n",
      "Epoch: 165/250, Loss: 12.8895, Bleu: 0.00000, Elapsed Time: 62.3489\n",
      "\n",
      "Epoch: 166/250, Loss: 0.0756, Bleu: 0.99005, Elapsed: 116.48 secpsed: 116.48 sec\n",
      "Epoch: 166/250, Loss: 13.9746, Bleu: 0.00000, Elapsed Time: 60.9165\n",
      "\n",
      "Epoch: 167/250, Loss: 0.0612, Bleu: 0.99312, Elapsed: 116.23 secpsed: 116.23 sec\n",
      "Epoch: 167/250, Loss: 13.7998, Bleu: 0.00000, Elapsed Time: 60.9012\n",
      "\n",
      "Epoch: 168/250, Loss: 0.0534, Bleu: 0.99320, Elapsed: 116.46 secpsed: 116.46 sec\n",
      "Epoch: 168/250, Loss: 13.0804, Bleu: 0.00000, Elapsed Time: 68.8374\n",
      "\n",
      "Epoch: 169/250, Loss: 0.0484, Bleu: 0.99766, Elapsed: 116.44 secpsed: 116.44 sec\n",
      "Epoch: 169/250, Loss: 14.0634, Bleu: 0.00000, Elapsed Time: 63.1476\n",
      "\n",
      "Epoch: 170/250, Loss: 0.0512, Bleu: 0.99174, Elapsed: 116.31 secpsed: 116.31 sec\n",
      "Epoch: 170/250, Loss: 13.4971, Bleu: 0.00000, Elapsed Time: 60.5303\n",
      "\n",
      "Epoch: 171/250, Loss: 0.0713, Bleu: 0.98746, Elapsed: 116.38 secpsed: 116.38 sec\n",
      "Epoch: 171/250, Loss: 13.1166, Bleu: 0.00000, Elapsed Time: 63.0258\n",
      "\n",
      "Epoch: 172/250, Loss: 0.5402, Bleu: 0.80951, Elapsed: 116.47 secpsed: 116.47 sec\n",
      "Epoch: 172/250, Loss: 12.5714, Bleu: 0.00000, Elapsed Time: 62.7780\n",
      "\n",
      "Epoch: 173/250, Loss: 0.8146, Bleu: 0.73159, Elapsed: 116.23 secpsed: 116.23 sec\n",
      "Epoch: 173/250, Loss: 13.3759, Bleu: 0.00000, Elapsed Time: 61.8672\n",
      "\n",
      "Epoch: 174/250, Loss: 0.3217, Bleu: 0.88909, Elapsed: 116.25 secpsed: 116.25 sec\n",
      "Epoch: 174/250, Loss: 13.4526, Bleu: 0.00000, Elapsed Time: 60.5988\n",
      "\n",
      "Epoch: 175/250, Loss: 0.1398, Bleu: 0.96207, Elapsed: 116.30 secpsed: 116.30 sec\n",
      "Epoch: 175/250, Loss: 13.5930, Bleu: 0.00000, Elapsed Time: 59.8397\n",
      "\n",
      "Epoch: 176/250, Loss: 0.0751, Bleu: 0.99084, Elapsed: 116.34 secpsed: 116.34 sec\n",
      "Epoch: 176/250, Loss: 13.1167, Bleu: 0.00000, Elapsed Time: 62.1891\n",
      "\n",
      "Epoch: 177/250, Loss: 0.0520, Bleu: 0.98901, Elapsed: 116.14 secpsed: 116.14 sec\n",
      "Epoch: 177/250, Loss: 14.8809, Bleu: 0.00000, Elapsed Time: 62.4513\n",
      "\n",
      "Epoch: 178/250, Loss: 0.0429, Bleu: 0.99880, Elapsed: 116.37 secpsed: 116.37 sec\n",
      "Epoch: 178/250, Loss: 14.0142, Bleu: 0.00000, Elapsed Time: 62.9845\n",
      "\n",
      "Epoch: 179/250, Loss: 0.0370, Bleu: 0.99584, Elapsed: 116.15 secpsed: 116.15 sec\n",
      "Epoch: 179/250, Loss: 14.0154, Bleu: 0.00000, Elapsed Time: 62.5767\n",
      "\n",
      "Epoch: 180/250, Loss: 0.0337, Bleu: 0.99581, Elapsed: 116.03 secpsed: 116.03 sec\n",
      "Epoch: 180/250, Loss: 13.6423, Bleu: 0.00000, Elapsed Time: 62.7784\n",
      "\n",
      "Epoch: 181/250, Loss: 0.0317, Bleu: 0.99924, Elapsed: 116.25 secpsed: 116.25 sec\n",
      "Epoch: 181/250, Loss: 14.1550, Bleu: 0.00000, Elapsed Time: 60.8171\n",
      "\n",
      "Epoch: 182/250, Loss: 0.0307, Bleu: 0.99641, Elapsed: 116.22 secpsed: 116.22 sec\n",
      "Epoch: 182/250, Loss: 13.6024, Bleu: 0.00000, Elapsed Time: 65.5101\n",
      "\n",
      "Epoch: 183/250, Batch: 194/249, Loss: 0.0259, Bleu: 1.00000, Elapsed: 90.66 sec"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, epochs=250, lr=0.001, device=device)\n",
    "# watch with: watch -d -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6cd3a-411f-4445-8bbd-e816f1350a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
